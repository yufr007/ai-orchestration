"""Reviewer agent - Code review and quality gates."""

from typing import Any

from src.agents.base import BaseAgent
from src.core.state import OrchestrationState, AgentRole
from src.tools.github_tools import GitHubTools


class ReviewerAgent(BaseAgent):
    """Agent responsible for code review."""

    def __init__(self):
        super().__init__(role=AgentRole.REVIEWER, temperature=0.1)
        self.github = GitHubTools()

    async def execute(self, state: OrchestrationState) -> dict[str, Any]:
        """Execute review logic."""
        repo = state["repo"]
        pr_number = state.get("pr_number") or (state.get("prs_created", [])[-1] if state.get("prs_created") else None)

        if not pr_number:
            return {"output": "No PR to review", "artifacts": {}}

        # Get PR details and diff
        pr_data = await self.github.get_pr(repo, pr_number)
        diff = await self.github.get_pr_diff(repo, pr_number)

        # Perform review
        review_comments = await self._review_changes(pr_data, diff)

        # Check quality gates
        approval_status = self._determine_approval_status(review_comments)

        # Post review
        await self._post_review(repo, pr_number, review_comments, approval_status)

        return {
            "review_comments": review_comments,
            "approval_status": approval_status,
            "output": f"Review: {approval_status} with {len(review_comments)} comments",
            "artifacts": {"pr_data": pr_data},
            "metadata": {"pr_number": pr_number},
        }

    async def _review_changes(self, pr_data: dict, diff: str) -> list[dict]:
        """Perform code review using LLM."""
        system_prompt = """You are a Staff Engineer performing code review.

Review criteria:
1. **Code Quality**: Clean, readable, maintainable
2. **Best Practices**: Follows language idioms and patterns
3. **Error Handling**: Proper exception handling and edge cases
4. **Performance**: Efficient algorithms and resource usage
5. **Security**: No vulnerabilities or secrets exposure
6. **Testing**: Adequate test coverage
7. **Documentation**: Clear docstrings and comments

Output JSON array of review comments:
[
  {
    "file": "path/to/file.py",
    "line": 42,
    "severity": "critical|major|minor|suggestion",
    "category": "security|performance|style|logic|testing|docs",
    "message": "Clear description of issue and suggested fix"
  }
]

If no issues, return empty array []."""

        user_message = f"""Pull Request: {pr_data.get('title', '')}

Description:
{pr_data.get('body', '')[:500]}

Diff:
{diff[:8000]}

Perform code review."""

        messages = self.format_messages(system_prompt, user_message)
        response = await self.llm.ainvoke(messages)

        # Parse JSON response
        import json

        try:
            comments = json.loads(response.content)
        except json.JSONDecodeError:
            comments = []

        return comments

    def _determine_approval_status(self, comments: list[dict]) -> str:
        """Determine approval status based on review comments."""
        if not comments:
            return "approved"

        # Count by severity
        critical = sum(1 for c in comments if c.get("severity") == "critical")
        major = sum(1 for c in comments if c.get("severity") == "major")

        if critical > 0:
            return "changes_requested"
        elif major > 0:
            return "changes_requested"
        else:
            return "approved"  # Only minor issues or suggestions

    async def _post_review(self, repo: str, pr_number: int, comments: list[dict], status: str) -> None:
        """Post review to GitHub PR."""
        if status == "approved":
            body = """## âœ… Code Review: APPROVED

**Assessment**: This implementation meets all quality standards.

### Highlights
- Clean, readable code
- Proper error handling
- Adequate test coverage
- Follows best practices

Ready for merge after CI passes.

---
*Auto-generated by AI Orchestration Platform*
"""
        else:
            body = """## ðŸš§ Code Review: CHANGES REQUESTED

**Assessment**: Some issues need to be addressed before merging.

### Issues by Severity
"""
            # Group by severity
            for severity in ["critical", "major", "minor", "suggestion"]:
                severity_comments = [c for c in comments if c.get("severity") == severity]
                if severity_comments:
                    emoji = {"critical": "ðŸ”´", "major": "ðŸŸ ", "minor": "ðŸŸ¡", "suggestion": "ðŸŸ¢"}
                    body += f"\n#### {emoji[severity]} {severity.upper()}\n"
                    for comment in severity_comments:
                        body += f"- **{comment['file']}:{comment['line']}** [{comment['category']}]: {comment['message']}\n"

            body += "\n---\n*Auto-generated by AI Orchestration Platform*"

        await self.github.add_pr_comment(repo, pr_number, body)


# Node function for LangGraph
async def reviewer_node(state: OrchestrationState) -> dict[str, Any]:
    """Reviewer node for LangGraph workflow."""
    agent = ReviewerAgent()
    return await agent.invoke(state)
